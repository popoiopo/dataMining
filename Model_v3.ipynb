{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(relevances: np.ndarray, positions: np.ndarray) -> float:\n",
    "    \"\"\"Compute Normalized Discounted Cumulative Gain based on:\n",
    "    - relevances: Numpy Array containing DCG Relevances (5 if booked, 1 if clicked)\n",
    "    - positions: Numpy Array containing Positions (The display order) \"\"\"\n",
    "    \n",
    "    positions_normalized = np.argsort(positions)\n",
    "    relevances_ordered = relevances[positions_normalized]\n",
    "    relevances_sorted = np.sort(relevances)[::-1]\n",
    "    \n",
    "    gain = 2 ** relevances_ordered - 1\n",
    "    ideal_gain = 2 ** relevances_sorted - 1\n",
    "    \n",
    "    discount = np.log2(np.arange(len(positions)) + 2)\n",
    "    \n",
    "    DCG = np.sum(gain / discount)\n",
    "    IDCG = np.sum(ideal_gain / discount)\n",
    "    \n",
    "    return DCG / IDCG\n",
    "\n",
    "\n",
    "def nDCG_mean(dataframe: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Mean Normalized Discounted Cumulative Gain on DataFrame\n",
    "    DataFrame must have fields: [srch_id, relevance, position]\n",
    "    \"\"\"\n",
    "    \n",
    "    nDCG_sum = 0.0\n",
    "    \n",
    "    searches = dataframe.groupby('srch_id')\n",
    "    \n",
    "    for name, search in searches:\n",
    "        nDCG_sum += nDCG(search.relevance.values, search.position.values)\n",
    "    return nDCG_sum / len(searches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load That Shit (does take a while)\n",
    "df = pd.read_csv(\"data/training_set_VU_DM_2014.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Relevance Column to DataFrame\n",
    "relevance = np.zeros(len(df))\n",
    "relevance[df['click_bool'] == 1] = 1\n",
    "relevance[df['booking_bool'] == 1] = 5\n",
    "\n",
    "df['relevance'] = relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorganize DataFrame (a.k.a. throw out competitor info): handy for tweaking/overview?\n",
    "df = df[[\n",
    "    # ID\n",
    "    'srch_id',\n",
    "    \n",
    "    # Labels (to predict)\n",
    "    'position',\n",
    "    'relevance',\n",
    "    'click_bool',\n",
    "    'booking_bool',\n",
    "    \n",
    "    # Per Seach Features\n",
    "    'site_id',\n",
    "    'date_time',\n",
    "    'srch_destination_id',\n",
    "    'srch_length_of_stay',\n",
    "    'srch_booking_window',\n",
    "    'srch_adults_count',\n",
    "    'srch_children_count',\n",
    "    'srch_room_count',\n",
    "    'srch_saturday_night_bool',\n",
    "    'srch_query_affinity_score',\n",
    "    'orig_destination_distance',\n",
    "    \n",
    "    # Property Features\n",
    "    'price_usd',\n",
    "    'promotion_flag',\n",
    "    'prop_country_id',\n",
    "    'prop_id',\n",
    "    'prop_starrating',\n",
    "    'prop_review_score',\n",
    "    'prop_brand_bool',\n",
    "    'prop_location_score1',\n",
    "    'prop_location_score2',\n",
    "    'prop_log_historical_price',\n",
    "    \n",
    "    # Visitor Features\n",
    "    'visitor_location_country_id',\n",
    "    'visitor_hist_starrating',\n",
    "    'visitor_hist_adr_usd',\n",
    "    \n",
    "    # Random Order\n",
    "    'random_bool',\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix NaN's\n",
    "# Pandas Might Complain about me overwriting stuff\n",
    "affinity = df.srch_query_affinity_score\n",
    "affinity[np.isnan(affinity)] = np.min(affinity)\n",
    "\n",
    "distance = df.orig_destination_distance\n",
    "distance[np.isnan(distance)] = -1\n",
    "\n",
    "review = df.prop_review_score\n",
    "review[np.isnan(review)] = -1\n",
    "\n",
    "location_2 = df.prop_location_score2\n",
    "location_2[np.isnan(location_2)] = np.mean(location_2)\n",
    "\n",
    "visitor_hist_stars = df.visitor_hist_starrating\n",
    "visitor_hist_stars[np.isnan(visitor_hist_stars)] = -1\n",
    "\n",
    "visitor_hist_usd = df.visitor_hist_adr_usd\n",
    "visitor_hist_usd[np.isnan(visitor_hist_usd)] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "srch_id                        :D\n",
      "position                       :)\n",
      "relevance                      :)\n",
      "click_bool                     :)\n",
      "booking_bool                   :)\n",
      "site_id                        :P\n",
      "date_time                      :)\n",
      "srch_destination_id            :D\n",
      "srch_length_of_stay            :)\n",
      "srch_booking_window            :)\n",
      "srch_adults_count              :P\n",
      "srch_children_count            :)\n",
      "srch_room_count                :)\n",
      "srch_saturday_night_bool       :P\n",
      "srch_query_affinity_score      :)\n",
      "orig_destination_distance      :P\n",
      "price_usd                      :D\n",
      "promotion_flag                 :P\n",
      "prop_country_id                :D\n",
      "prop_id                        :)\n",
      "prop_starrating                :P\n",
      "prop_review_score              :D\n",
      "prop_brand_bool                :P\n",
      "prop_location_score1           :)\n",
      "prop_location_score2           :P\n",
      "prop_log_historical_price      :)\n",
      "visitor_location_country_id    :)\n",
      "visitor_hist_starrating        :P\n",
      "visitor_hist_adr_usd           :)\n",
      "random_bool                    :)\n"
     ]
    }
   ],
   "source": [
    "# Check NaN's per Column, if only smileys appear, you're fine ^^\n",
    "\n",
    "from random import choice\n",
    "smileys = [':)', ':D', ':P']\n",
    "\n",
    "for column in df.columns:\n",
    "    print(\"{:30s} {}\".format(column, \"NaN\" if df[column].isnull().any() else choice(smileys)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Random Fraction of Searches of DataFrame (To Speed Up Shit)\n",
    "# (This does take a while though...)\n",
    "RANDOM_FRACTION = 0.1\n",
    "selection = df.groupby('srch_id').filter(lambda x: np.random.uniform() < RANDOM_FRACTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Train and Test from random selection, again per Search ID\n",
    "TEST_TRAIN_SPLIT = 0.8\n",
    "\n",
    "unique_search_ids = np.unique(selection.srch_id)\n",
    "mask = np.random.uniform(0, 1, len(unique_search_ids)) < TEST_TRAIN_SPLIT\n",
    "\n",
    "train = selection[selection.srch_id.isin(unique_search_ids[mask])]\n",
    "test = selection[selection.srch_id.isin(unique_search_ids[~mask])]\n",
    "\n",
    "train_features = train.iloc[:, 7:]\n",
    "train_labels = train['relevance']\n",
    "\n",
    "test_features = test.iloc[:, 7:]\n",
    "test_labels = test['relevance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train Regressor on Train Features and Train Labels (a.k.a. Relevances)\n",
    "# This should be fairly quick now :) (20 seconds?, idk)\n",
    "classifier = RandomForestRegressor()\n",
    "classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Predict Relevances\n",
    "predict_labels = classifier.predict(test_features)\n",
    "\n",
    "# Through Data to Calculate Score in new DataFrame\n",
    "# Note that predicted position = - predicted relevance\n",
    "result = pd.DataFrame({\n",
    "    'srch_id': test.srch_id,\n",
    "    'relevance': test.relevance,\n",
    "    'position': -predict_labels})\n",
    "\n",
    "print(\"Prediction:\", nDCG_mean(result))\n",
    "\n",
    "\n",
    "# Throw Random Positions in the Mix, to show we're doing better than Random :)\n",
    "result = pd.DataFrame({\n",
    "    'srch_id': test.srch_id,\n",
    "    'relevance': test.relevance,\n",
    "    'position': np.random.uniform(0, 1, len(test.relevance))\n",
    "})\n",
    "\n",
    "print(\"Random:\", nDCG_mean(result))\n",
    "\n",
    "\n",
    "# Plot Feature Importances Graph\n",
    "plt.barh(np.arange(len(test_features.columns)), classifier.feature_importances_,\n",
    "       tick_label=test_features.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
